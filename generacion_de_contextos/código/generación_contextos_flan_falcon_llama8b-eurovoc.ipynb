{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1194530-e671-4df9-b12e-f529527c36fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch langchain pandas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978c7274-0302-4453-8ae2-0e375775c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c816f7-4706-4bfd-aa02-94d2f8b4bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27a7d47-1472-400a-96e0-25f01c164d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install torch --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a89d23-5aa4-4ff5-a63d-51b11a8c06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers accelerate optimum\n",
    "!pip install --no-build-isolation auto-gptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b8ab2f-8c08-4eb6-80c7-41fcc3681745",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "\n",
    "# Archivos\n",
    "input_csv = \"eurovoc_con_definiciones.csv\"\n",
    "output_csv = \"eurovoc_terminos_contexto_generado_llama8b_inst_0-shot.csv\"\n",
    "\n",
    "# Cargar CSV\n",
    "try:\n",
    "    df = pd.read_csv(input_csv, encoding=\"utf-8\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar el CSV: {e}\")\n",
    "    raise\n",
    "\n",
    "# Modelo sin cuantizar\n",
    "model_id = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16,    # si tienes GPU con soporte fp16\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "modelo_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Generar ventana\n",
    "def generar_ventana(termino, contextos):\n",
    "    prompt = (\n",
    "        f\"<s>[INST] Eres un experto en lingüística jurídica.\\n\"\n",
    "        f\"Dado el conjunto de información semántica para el término \\\"{termino}\\\", \"\n",
    "        f\"genera una ventana de contexto clara y precisa en español \"\n",
    "        f\"(máx. 512 palabras) que permita deducir el sentido correcto del término \"\n",
    "        f\"dentro del dominio del derecho laboral.\\n\\n\"\n",
    "        f\"Contextos:\\n{contextos}\\n\\n\"\n",
    "        f\"[/INST]\"\n",
    "    )\n",
    "    try:\n",
    "        output = modelo_pipeline(\n",
    "            prompt, \n",
    "            max_new_tokens=200, \n",
    "            do_sample=False,\n",
    "            temperature=0.7, \n",
    "            top_p=0.95, \n",
    "            repetition_penalty=1.1\n",
    "        )[0][\"generated_text\"]\n",
    "        return output.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error con '{termino}': {e}\")\n",
    "        return \"Error en la generación\"\n",
    "\n",
    "# Procesar\n",
    "columnas_contexto = [col for col in df.columns if 'contexto' in col.lower()]\n",
    "resultados = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Generando contextos\"):\n",
    "    termino = row['Término']\n",
    "    contextos = \" \".join([str(row[col]) for col in columnas_contexto if pd.notna(row[col])])\n",
    "    resultados.append({\n",
    "        \"Termino\": termino,\n",
    "        \"Ventana_de_contexto\": generar_ventana(termino, contextos)\n",
    "    })\n",
    "\n",
    "# Guardar\n",
    "pd.DataFrame(resultados).to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Contextos generados y guardados en:\", output_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4bbbc1-c274-4302-810d-f03a0fb88ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15861eb7a8894b54927a9253af94a354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta a tus archivos\n",
    "input_csv = \"eurovoc_con_definiciones.csv\"\n",
    "output_csv = \"eurovoc_contexto_generado_llama8b_inst_1shot.csv\"\n",
    "\n",
    "# Cargar CSV\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Inicializar pipeline directamente\n",
    "modelo_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Generar contexto\n",
    "def generar_ventana(termino, contextos):\n",
    "    prompt = (\n",
    "        \n",
    "\n",
    "f\"Eres un experto en lingüística jurídica.\\n\"\n",
    "        f\"Dado el conjunto de información semántica para el término \\\"{termino}\\\", genera una ventana de contexto clara \\n\"\n",
    "        f\"y precisa en español, de máximo 512 palabras. Debe ser una ventana de contexto que permita deducir\\n\\n\"\n",
    "        f\"el sentido correcto del término dentro del dominio del derecho laboral\\n\\n\"\n",
    "        f\"Ejemplo 1:\\n\"\n",
    "        f\"Término: jornada de trabajo\\n\"\n",
    "        f\"Contextos:\\n\"\n",
    "        f\"condiciones y organización del trabajo | jornada laboral | organización del trabajo | horario de trabajo; horario flexible; trabajo dominical; jornada legal; tiempo de descanso; reducción del tiempo de trabajo; trabajo nocturno; trabajo por turnos; jornada intensiva; hora extraordinaria\\n\"\n",
    "        f\"Respuesta:\\n\"\n",
    "        f\"La jornada de trabajo hace referencia al número de horas que tiene que hacer una persona trabajadora así como la distribución diaria, semanal o mensual de esas horas de trabajo.\\n\\n\"\n",
    "        f\"Término: {termino}\\n\"\n",
    "        f\"Contextos:\\n{contextos}\\n\\n\"\n",
    "        f\"Respuesta:\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    try:\n",
    "        output = modelo_pipeline(prompt, max_new_tokens=200)[0][\"generated_text\"]\n",
    "        return output.split(\"Respuesta:\")[-1].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error con '{termino}': {e}\")\n",
    "        return \"Error en la generación\"\n",
    "\n",
    "# Aplicar\n",
    "resultados = []\n",
    "for _, row in df.iterrows():\n",
    "    termino = row['Término']\n",
    "    contextos = \" \".join([str(row[col]) for col in df.columns if 'contexto' in col.lower() and pd.notna(row[col])])\n",
    "    resultados.append({\n",
    "        \"Termino\": termino,\n",
    "        \"Ventana_de_contexto\": generar_ventana(termino, contextos)\n",
    "    })\n",
    "\n",
    "# Guardar resultados\n",
    "pd.DataFrame(resultados).to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Contextos generados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e372eed6-174a-4857-b395-5534c916c907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Ruta a tus archivos\n",
    "input_csv = \"eurovoc_con_definiciones.csv\"\n",
    "output_csv = \"eurovoc_contexto_generado_llama8b_inst_3shot.csv\"\n",
    "\n",
    "# Cargar CSV\n",
    "df = pd.read_csv(input_csv)\n",
    "\n",
    "# Inicializar pipeline directamente\n",
    "modelo_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"meta-llama/Llama-3.1-8B-Instruct\",\n",
    "    device=-1\n",
    ")\n",
    "\n",
    "# Generar contexto\n",
    "def generar_ventana(termino, contextos):\n",
    "    prompt = (\n",
    "        \n",
    "\n",
    "  f\"Eres un experto en lingüística jurídica.\\n\"\n",
    "        f\"Dado el conjunto de información semántica para el término \\\"{termino}\\\", genera una ventana de contexto clara \\n\"\n",
    "        f\"y precisa en español, de máximo 512 palabras. Debe ser una ventana de contexto que permita deducir\\n\\n\"\n",
    "        f\"el sentido correcto del término dentro del dominio del derecho laboral\\n\\n\"\n",
    "        f\"Ejemplo 1:\\n\"\n",
    "        f\"Término: jornada de trabajo\\n\"\n",
    "        f\"Contextos:\\n\"\n",
    "        f\"condiciones y organización del trabajo | jornada laboral | organización del trabajo | horario de trabajo; horario flexible; trabajo dominical; jornada legal; tiempo de descanso; reducción del tiempo de trabajo; trabajo nocturno; trabajo por turnos; jornada intensiva; hora extraordinaria\\n\"\n",
    "        f\"La jornada de trabajo hace referencia al número de horas que tiene que hacer una persona trabajadora así como la distribución diaria, semanal o mensual de esas horas de trabajo.\\n\\n\"\n",
    "        f\"Respuesta:\\n\"\n",
    "        f\"Ejemplo 2:\\n\"\n",
    "    f\"Término: maternidad\\n\"\n",
    "    f\"Contextos:\\n\"\n",
    "    f\"protección social | permiso social.\\n\"\n",
    "    f\"Respuesta:\\n\"\n",
    "    f\"Situación protegida por el sistema de la Seguridad Social por vía de subsidios y suspensión del contrato por riesgo durante el embarazo y durante la lactancia natural.\\n\\n\"\n",
    "\n",
    "    f\"Ejemplo 3:\\n\"\n",
    "    f\"Término: despido colectivo\\n\"\n",
    "    f\"Contextos:\\n\"\n",
    "    f\"de trabajo, siempre que su existencia haya sido debidamente constatada conforme a lo dispuesto en el artículo 51.7. i) Por despido colectivo fundado en causas económicas, técnicas, organizativas o de producción.\\n\"\n",
    "    f\"empleo | despido.\\n\"\n",
    "    f\"Respuesta:\\n\"\n",
    "    f\"Extinción de la relación laboral a voluntad del empresario que afecta a un número de trabajadores en un período de tiempo delimitado legalmente y sometido a reglas especiales de tramitación igualmente establecidas legalmente.\\n\\n\"\n",
    "\n",
    "    f\"Término: {{termino}}\\n\"\n",
    "        f\"Término: {termino}\\n\"\n",
    "        f\"Contextos:\\n{contextos}\\n\\n\"\n",
    "        f\"Respuesta:\"\n",
    "    )\n",
    "\n",
    "    \n",
    "    try:\n",
    "        output = modelo_pipeline(prompt, max_new_tokens=200)[0][\"generated_text\"]\n",
    "        return output.split(\"Respuesta:\")[-1].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error con '{termino}': {e}\")\n",
    "        return \"Error en la generación\"\n",
    "\n",
    "# Aplicar\n",
    "resultados = []\n",
    "for _, row in df.iterrows():\n",
    "    termino = row['Término']\n",
    "    contextos = \" \".join([str(row[col]) for col in df.columns if 'contexto' in col.lower() and pd.notna(row[col])])\n",
    "    resultados.append({\n",
    "        \"Termino\": termino,\n",
    "        \"Ventana_de_contexto\": generar_ventana(termino, contextos)\n",
    "    })\n",
    "\n",
    "# Guardar resultados\n",
    "pd.DataFrame(resultados).to_csv(output_csv, index=False, encoding=\"utf-8\")\n",
    "print(\"✅ Contextos generados.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed3ce58-a5b2-4819-8d9b-0f267c6128b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
